%Page 80
\[ D_i = \frac{ [ \mbox{var}(\hat{\beta})]^{-1} }{\mbox{rank}(\textbf{X}) \]


%===============================================%

%Page 497 
\section*{20.3  Influence Diagnostics}

\begin{itemize}
\item Cook's Distance
\item Likelihood Distance
\end{itemize}

%------------%
\subsection*{Preparatory Steps}

The \texttt{formula()} can recall the definition of the model defining the mean structure.

Auxillary Function \texttt{logLik1()} which is designed to calculate a contribution of a given subject to the overall likelihood for a given model.


The number of degrees of freedom reported by loglik is equal to 8. This corresponds
to the total number of parameters in the model.
%--------------------------------------------%
% Page 498 Top

Part A
\begin{framed}
\begin{verbatim}
 <- update(fm16.5)


  
logLik()
\end{verbatim}
\end{framed}

%------%

Part B

\begin{framed}
\begin{verbatim}

beta0 <- fixef(fm16.5ml}

beta0

colnames(vcovb) <- names(beta0)
vcovb

\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 498 Bottom

We extract the $\textbf{\beta}$ estimates and their estimated variance covariance matrix.

Towards this end, we use the functions \fixef) and vcov() respectively, we can save these estimates and the matrix as objects \texttt{beta0} and 
\texttt{vcovb} respectively.

With the help of the \texttt{abbreviate} function the names of the beta estimates are shortened to simplify the display of content.

%--------------------------------------------%
% Page 499 Top
An auxillary function logLik1()

we used the \texttt{logLik()} function to obtain the value of the log-likelihood for the fitted model.
It should be noted that the function returns the log-likelihood evaluated at the set of the


The auxillary functon logLik1() has been included in the package nlmeU.

estimated fixed effects and variance-covariance parameters and for the data set, to which the model
is fitted. In the context of influence diagnostics, we need a more general function that allows




\begin{description}
\item[ \texttt{modfit} ] an object of class \textit{lme} representing the lme model fited to a given dataset using ML estimation.
\item[ \texttt{dt1}] a dataframe with data for one subject, for whom the likelihood function to be evaluated
\item[ \texttt{dtInit }] an optional auxillary data frame
\end{description}

%--------------------------------------------%
% Page 499 Bottom

The dataframe provided in the argument \texttt{dt1} is typically created by choosing a subset with one subject from the data used to obtain the model fit object specified in the \texttt{modfit} argument.
However, in general, any pluasible fata for one subject , not necessarily from the dataset used to fit the model, can be used.


The auxillary data provided in the argument dtInit is temporarily appended to the dt1 data. during the logLik() function execution.



The \texttt{logLik1()} function returns the numeric contributions of the single subject, with the data specified in the dt1 argument, to the log likelihood
for the model specified in the modfit argument.



% ----------% 
% New Section 
Contributions of Individual Subjects to the log-likelihood for fitted model

%--------------------------------------------%
% Page 500 top

\begin{framed}
\begin{verbatim}

lLik.i <- as.vector(lLik.i)

lLik.i[1:5]
sum(lLik.i)

\end{verbatim}
\end{framed}
%-------------------%

Plot of individual contributions to the log-likelihood (traditional graphics)
\begin{framed}
\begin{verbatim}

subject.c <-
subject.x <- 
plot()
points()
text()
\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 500 Bottom

next we use the function \texttt{logLik1()} to compute the loglikelihood
contributions for all subjects.
%--------------------------------------------%
% Page 501 top

We present the syntax to plot the per-observation individual log-likelihood contributions.
First, with the help of the by() function, we create the array \texttt{nx} , which contains the number
of observations

%--------------------------------------------%
% Page 501 Bottom

\section{Influence Diagnostics}

We use the results of the preparatory steps to perform influence-diagnostic calculations for the model.
More specifically we evaluate the influence of every subject included in the data set.


We create a list containing the results of fitted model the ``leave-one-subject-out" (LOO)
datasets and explore its contents.

We define the function \texttt{lmeU()}, which fits the model to the data from the armd

when the function lmeU() is executed, and LOO data frame, named dfU, is created with thesubject, indicated by the cx argument.

Subsequently model is fitted by dfI by applying the 


next, with the help of the function lapply(), we apply the lmeU() to the consecutive elements of the character vector subject.c.

As a result, we obtain the list lmeUall, with lme-class model fit objects as elements. The model-fit objects contains the result of fitting model
M16.5.
%--------------------------------------------%
% Page 502 All

Finally, we name the components of the \texttt{lmeUall()} list using the subjects idenifier stored in the vector subject.c.

This technique is computationally expensive, as it required the model to be fitted $m$ number of times, omitting one of the $m$ cases each time.

Execution time can be improved if we decided to perform a reduced number of likelihood iterations, instead of performing iterations until there is convergence.

The values, based on the first few iterations, are expected to give a fairly good approximation of the LOO estimates.

%-------%

The names of the first six components are printed out using the function \texttt{names()}.

To extract the LOO data frame for, e.g., the subject ``6", we refer to the ``6" compoment of the
\texttt{lmeUall} list.

The extracted data frame is stored in the object \texttt{dataU6}. By using the function dim() we can check the dimensions of the data frame.



%--------------------------------------------%
% Page 503 Top
Model is fitted to a sequence of "leave-one-subject-out" out data sets.


\begin{framed}
\begin{verbatim}

 # back - what is cx?
 # cx is Case identity
lmeU <- function(cx){
	dfU <- subset(myData, subject !=cx)
	update(mymodel,data=dfU)
}

 # what is lmeU?

lmeUall <- lapply(subject.c, lmeU)
\end{verbatim}
\end{framed}
%------------------------%
Exploring the contents of the lmeUall object.
\begin{framed}
\begin{verbatim}
names(lmeUall)
dataU6 <- lmeUall[["6"]]$data
dim(dataU6)
unique(dataU6$subject)[1:6]
\end{verbatim}
\end{framed}

%-------------------------------------------%
% Page 503 and 504 Bottom
% PArt 20.3.2.2. Likelihood Distacnce for fitted Model
Galecki presents the code used to calculate and plot individial likelihood displacements.

For an LMM, it is required the computation of the full log-likelihood for $\hat{\textbf{\theta}}$, the ML estimate for 
$\textbf{\theta}$ obtained by fitting the model to all data, and for $\hat{\textbf{\theta}}_(-i)$, the ML estimate obtained
by fitting the model to the data with the $i-$th subject excluded.

Note that both values of the log-likelihood, used in the definition of the likelihood displacement, should be 
calculated taking into account all observations.

%---------%


Galeck creates an auxillary function \textt{lLik()} which , for a given subject indicated by the main argument, extracts the lme model fit object for the
corresponding LOO data.


The corresponding log-likelihood function is extracted from the lmeU with the help of the logLik()


The returned value \texttt{lLikU + lLik.s} is the log-likelihood evaluated for all observations, using the displaced estimates of the model parameters.

%------------------------------------------%
% Page 504 Top

Calculation of the likelihood displacement

\begin{framed}
\begin{verbatim}

lLik <- function(cx)
   {
   lmeU <- lmeUall[[cx]]
   lLikU <- logLik(lmeU, REML = FALSE)
   df.s <- subset(armd,subject == cx)
 
   lLik.s <- logLik1(lmeU,df.s)

   return(lLikU + lLik.s)
   }

lLikUall <- apply(subject.c,lLik)

\end{verbatim}
\end{framed}

%--------------------%
% Part 2
% Plot of the likelihood displacement with an indication of outlying values.
%

\begin{framed}
\begin{verbatim}

names(dif.2Lik) <- subject.c #subjects ids assigned
outL <- dif.2Lik > 0.5

dif.2Lik[outL]

## Plot Component

libary(lattice)

subject.f <- factor(subject.c, levels = subject.c)

myPanel <- function(x,y, ...){
  x1 <- as.numeric(x)
  panel.xyplot(x1,y, ... )
  ltext(x1[outL],y[outL], subject.c[outL]) # outlying LDis
  }

dtp <- dotplot(dif.2Lik ~subject.f, panel = myPanel, type= "h")

 # ggplot?
lxlims <- length(dtp$x.limits)

update(dtp,xlim=rep(" ", lxlims),grid= "h")
\end{verbatim}
\end{framed}

%------------------------------------------%
% Page 505 Top

By applying the \texttt{summary()} function to the vector, we obtain summary statistics of the computed likelihood-displacement values.

we create the logical output vector outL which indicates the subjects with the values of the 
likelihood displacement exceeding say 0.5.

From the printout of the selected elements of the vectir dif.2Lik it follows that there are
seven such subjects.


We then use the function \texttt{dotplot()} from the package lattice to plot the 
likelihood distance value for all subjects.

The x-axis of the plot is constructed using numeric representation of the \texttt{numeric.f} factor, containing values ranging from 1 to 234.
%------------------------------------------%
% Page 505 Bottom
\section{20.3.2.3. Cook's Distance for the $\beta$ estimates}

Cook's distance for the $\beta$ estimates was defined in (4.26) for the classical LM.
The definition can be extended to the LMMs in a straightforward manner.

%------------------------------------------%
% Page 506 top

Part 2 plot of cook's distance using traditional graphics

# Annotation Component

\begin{framed}
\begin{verbatim}

betaUall <- sapply(lmeUall,fixef)

vb.inv <- solve(vcovb)

cookDfun <- function(betaU){
   dbetaU <- betaU - beta0
   cookD.value <- t(dbetaU) %*% vb.inv %*% dbetaU
   }
\end{verbatim}
\end{framed}

%----------------%
Plot of Cook's Distance using traditional graphics. 
Outlying values annotated.

\begin{framed}
\begin{verbatim}
outD <- cookD > 0.03


#Create the Stick plot
plot(CookD ~subject.c, 
  ylab="Cook's Distance", type="h")

text()
points()
\end{verbatim}
\end{framed}

%------------------------------------------%
% Page 506 bottom 
Cook's distance for the $beta$ estimates were defined bu 4.26 for the classical LM model.


Next we compute the inverse of the variance covariance matrix \hat{\beta} using the solve() function.
We store the resulting matrix in the object \texttt{vb.inv}.

Subsequently we define the function \texttt{cookDfun()} which, for a vector given in
the \texttt{betaU} argument, computes the value of the numerator of Cook's Distance, as in (4.26).

The function is then applied sequentially to all columns of the matrix \texttt{betaUall}.


The resultant vector is divided by the number of the fixed effects coefficients, which, under the assumption that the design matrix is of full rank, 
is equivalent to the rank of the design matrix.

%------------------------------------------%
% Page 507 all


The outcome is stored in the vector \textt{cookD} and contains the values of cooks distanced for all subjects.

We create the logical vector outD which indicates the subjects with cook's distance values that exceed 0.03.

Present the scatterplot matrix of the two-dimensional projections of the differences.
\[  \frac{\hat{\textbf{beta}_{(-i)} - \hat{\textbf{beta}} }{\hat{se}(\hat{beta})} \]
for all pairs of the fixed-effects coefficients.

%-------%
The plot was generated using the \texttt{splom} function. The main argument of the 
function was obtained by subtracting the beta0 vector from the rows of the transposed
betaUall matrix.

%-------%
The labels used in the panels located on the diagonal of the figure provide the fixed estimates of fixed effects coefficients
of the model and their estimates SEs.
The panels above the diagonal include points for all subjects.
The points for non-outlying values are plotted using small size open circles.
The five outlying values are plotted using different plotting symbols defined in the
legend of the figure at the top of the graph.

%------------------------------------------%
% Page 508 All +  top of Page 509

The effect of removal of this subject on the estimates of the remaining fixed-effects coefficients is relatively small.
In contrast, removing the subject ``227" affects the estimate of all fixed-effects coefficients to a different degree and in different directions.

More specifically, the intercept is driven towards lower values : the positive slope associated with visual acuity at baseline visual0, is further increased, the negative slope associated with \texttt{time} is brough closer to zero, and the treatment effect is attenuated.

% Top of Page 509

Overall we note that the effect of removing any of the subjects on the fixed effects estimates is very small, as it does not exceed 0.05 of the SE of any of the  estimates.

%-------------------------------------------%
%Page 509 Top
\section{Simulation of the Dependent Variable}

We cosnider simualtions of the dependent variable, based on the marginal distribution 
implied by the fitted model.
Towards this end, we have developed \texttt{simulateY()}, which can be used for objects of class lme.

We note that the function is different from simulate.lme(), available in the nlme in that the latter returns
simulation-based REML and/or ML values and not the value of the dependent variable.

We demonstrate the use of the \texttt{simulateY()} function to create the empirical distribution of the \textbf{\beta} estimates.
As an example, we consider the model which was fitted to the armd data.

Note however that the presented syntax is fairly general can be used for other LMEs as well.

We apply the function \texttt{simulateY()} to the object fm16.5ml.


%-------------------------------------------%
%Page 509 Bottom

\begin{framed}
\begin{verbatim}
library(nlmeU)
simY <- simulateY(fm16.5ml, nsim=1000)


simYsumm <- apply( simY, MARGIN = 2, 
 FUN = function(y){

     }
   )


simYsumm[[1]]

# \hat{\beta} for the 1st simulation
\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 510 Top

There is a second argument \texttt{nsim} that indicated how many simulations 

The auxillary function performs the following steps

\begin{itemize}
\item the dependent variable visual is the \texttt{auxDt} data frame is replaced wiht a new set of simulated values contained in the vector $y$.
\item Model M16.5 is fitted to the modified data frame
\item the vector beta with the estimates of the fixed effects coefficients is extracted from the summary of the model-fit object with the help of the \texttt{fixef()} function.
\item The vector of estimates is returned as a list with one component named \texttt{beta}.
\end{itemize}

They are drawn from the marginal distribution of the dependent variable implied by the fitted model.

%--------------------------------------------%
% Page 510 Bottom


It should be mentioned that the creation of the simYsumm list involves refitting the model many times, and it therefore takes a long time.

Toward this end, with the help of the \texttt{sapply()} function, we extrac the vectors with the values of \hat{\beta} for each simulation for the list
-object \texttt{simYsumm} and bind them column-wise into the \texttt{betaE}.

Then we use the function \texttt{rowMeans()} to compute the mean values of the columns (i.e. accross the rows) of betaE.



%--------------------------------------------%



logLik1 Calculates contribution of one subject to the log-likelihood
Description
This function is generic; method functions can be written to handle specific classes of objects.
Usage
logLik1(modfit, dt1, dtInit)

%======================================================================%


simulateY Simulates values of the dependent variable based on a model fit
Description
This function is generic; method functions can be written to handle specific classes of objects.
Usage
simulateY(object, nsim = 1, seed = NULL, ...,
verbose = FALSE, sigma)
Arguments
object an object with a model fit for which dependent variable is to be simulated.
nsim number of simulations. nsim = 1 by default.
seed integer scalar used to initiate random numbers generator.
... some methods for this generic function may require additional arguments.
verbose logical. If TRUE basic information about arguments is provided. By default set
to FALSE.
sigma numeric scalar. Allows to perform simulations employing alternative value of
the scale parameter.
Value
numeric matrix. Number of columns determined by nsim argument.

%=============================================================================%
Pwr Calculates power based on a model fit
Description
This function is generic; method functions can be written to handle specific classes of objects.
Usage
Pwr(object, ...)
Arguments
object an object containing the results returned by a model fitting function (e.g., lme).
... some methods for this generic function may require additional arguments.
Value
numeric scalar value.
Author(s)
Andrzej Galecki and Tomasz Burzykowski
See Also
Pwr.lme

My search just now found no mention of Cook's distance or influenc 
measures.  The closest I found was an unanswered question on this from 
April 2003 (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/4797.html).

  Beyond that, there is an excellent discussion of "Examining a Fitted 
Model" in Sec. 4.3 (pp. 174-197) of Pinheiro and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer).  Pinheiro and Bates 
decided NOT to include plots of Cook's distance among the many 
diagnostics they did provide.  However, 'plot(fit.lme)' plots 
'standardized residuals' vs. predicted or 'fitted values'.  Wouldn't 
points with large influence stand apart from the crowd in terms of 
'fitted value'?

	  Of course, there are many things other one could do to get at related 
information, including reading the code for 'influence' and 'lme', and 
figure out from that how to write an 'influence' method for an 'lme' 
object.  However, that is far beyond what you asked and what I have time 
now to disucss.

%=================================================================================%


%Page 80
\[ D_i = \frac{ [ \mbox{var}(\hat{\beta})]^{-1} }{\mbox{rank}(\textbf{X}) \]


%===============================================%

%Page 497 
\section*{20.3  Influence Diagnostics}

\begin{itemize}
\item Cook's Distance
\item Likelihood Distance
\end{itemize}

%------------%
\subsection*{Preparatory Steps}

The \texttt{formula()} can recall the definition of the model defining the mean structure.

Auxillary Function \texttt{logLik1()} which is designed to calculate a contribution of a given subject to the overall likelihood for a given model.


The number of degrees of freedom reported by loglik is equal to 8. This corresponds
to the total number of parameters in the model.
%--------------------------------------------%
% Page 498 Top

Part A
\begin{framed}
\begin{verbatim}
 <- update(fm16.5)


  
logLik()
\end{verbatim}
\end{framed}

%------%

Part B

\begin{framed}
\begin{verbatim}

beta0 <- fixef(fm16.5ml}

beta0

colnames(vcovb) <- names(beta0)
vcovb

\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 498 Bottom

We extract the $\textbf{\beta}$ estimates and their estimated variance covariance matrix.

Towards this end, we use the functions \fixef) and vcov() respectively, we can save these estimates and the matrix as objects \texttt{beta0} and 
\texttt{vcovb} respectively.

With the help of the \texttt{abbreviate} function the names of the beta estimates are shortened to simplify the display of content.

%--------------------------------------------%
% Page 499 Top
An auxillary function logLik1()

we used the \texttt{logLik()} function to obtain the value of the log-likelihood for the fitted model.
It should be noted that the function returns the log-likelihood evaluated at the set of the


The auxillary functon logLik1() has been included in the package nlmeU.

estimated fixed effects and variance-covariance parameters and for the data set, to which the model
is fitted. In the context of influence diagnostics, we need a more general function that allows




\begin{description}
\item[ \texttt{modfit} ] an object of class \textit{lme} representing the lme model fited to a given dataset using ML estimation.
\item[ \texttt{dt1}] a dataframe with data for one subject, for whom the likelihood function to be evaluated
\item[ \texttt{dtInit }] an optional auxillary data frame
\end{description}

%--------------------------------------------%
% Page 499 Bottom

The dataframe provided in the argument \texttt{dt1} is typically created by choosing a subset with one subject from the data used to obtain the model fit object specified in the \texttt{modfit} argument.
However, in general, any pluasible fata for one subject , not necessarily from the dataset used to fit the model, can be used.


The auxillary data provided in the argument dtInit is temporarily appended to the dt1 data. during the logLik() function execution.



The \texttt{logLik1()} function returns the numeric contributions of the single subject, with the data specified in the dt1 argument, to the log likelihood
for the model specified in the modfit argument.



% ----------% 
% New Section 
Contributions of Individual Subjects to the log-likelihood for fitted model

%--------------------------------------------%
% Page 500 top

\begin{framed}
\begin{verbatim}

lLik.i <- as.vector(lLik.i)

lLik.i[1:5]
sum(lLik.i)

\end{verbatim}
\end{framed}
%-------------------%

Plot of individual contributions to the log-likelihood (traditional graphics)
\begin{framed}
\begin{verbatim}

subject.c <-
subject.x <- 
plot()
points()
text()
\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 500 Bottom

next we use the function \texttt{logLik1()} to compute the loglikelihood
contributions for all subjects.
%--------------------------------------------%
% Page 501 top

We present the syntax to plot the per-observation individual log-likelihood contributions.
First, with the help of the by() function, we create the array \texttt{nx} , which contains the number
of observations

%--------------------------------------------%
% Page 501 Bottom

\section{Influence Diagnostics}

We use the results of the preparatory steps to perform influence-diagnostic calculations for the model.
More specifically we evaluate the influence of every subject included in the data set.


We create a list containing the results of fitted model the ``leave-one-subject-out" (LOO)
datasets and explore its contents.

We define the function \texttt{lmeU()}, which fits the model to the data from the armd

when the function lmeU() is executed, and LOO data frame, named dfU, is created with thesubject, indicated by the cx argument.

Subsequently model is fitted by dfI by applying the 


next, with the help of the function lapply(), we apply the lmeU() to the consecutive elements of the character vector subject.c.

As a result, we obtain the list lmeUall, with lme-class model fit objects as elements. The model-fit objects contains the result of fitting model
M16.5.
%--------------------------------------------%
% Page 502 All

Finally, we name the components of the \texttt{lmeUall()} list using the subjects idenifier stored in the vector subject.c.

This technique is computationally expensive, as it required the model to be fitted $m$ number of times, omitting one of the $m$ cases each time.

Execution time can be improved if we decided to perform a reduced number of likelihood iterations, instead of performing iterations until there is convergence.

The values, based on the first few iterations, are expected to give a fairly good approximation of the LOO estimates.

%-------%

The names of the first six components are printed out using the function \texttt{names()}.

To extract the LOO data frame for, e.g., the subject ``6", we refer to the ``6" compoment of the
\texttt{lmeUall} list.

The extracted data frame is stored in the object \texttt{dataU6}. By using the function dim() we can check the dimensions of the data frame.



%--------------------------------------------%
% Page 503 Top
Model is fitted to a sequence of "leave-one-subject-out" out data sets.


\begin{framed}
\begin{verbatim}

 # back - what is cx?
 # cx is Case identity
lmeU <- function(cx){
	dfU <- subset(myData, subject !=cx)
	update(mymodel,data=dfU)
}

 # what is lmeU?

lmeUall <- lapply(subject.c, lmeU)
\end{verbatim}
\end{framed}
%------------------------%
Exploring the contents of the lmeUall object.
\begin{framed}
\begin{verbatim}
names(lmeUall)
dataU6 <- lmeUall[["6"]]$data
dim(dataU6)
unique(dataU6$subject)[1:6]
\end{verbatim}
\end{framed}

%-------------------------------------------%
% Page 503 and 504 Bottom
% PArt 20.3.2.2. Likelihood Distacnce for fitted Model
Galecki presents the code used to calculate and plot individial likelihood displacements.

For an LMM, it is required the computation of the full log-likelihood for $\hat{\textbf{\theta}}$, the ML estimate for 
$\textbf{\theta}$ obtained by fitting the model to all data, and for $\hat{\textbf{\theta}}_(-i)$, the ML estimate obtained
by fitting the model to the data with the $i-$th subject excluded.

Note that both values of the log-likelihood, used in the definition of the likelihood displacement, should be 
calculated taking into account all observations.

%---------%


Galeck creates an auxillary function \textt{lLik()} which , for a given subject indicated by the main argument, extracts the lme model fit object for the
corresponding LOO data.


The corresponding log-likelihood function is extracted from the lmeU with the help of the logLik()


The returned value \texttt{lLikU + lLik.s} is the log-likelihood evaluated for all observations, using the displaced estimates of the model parameters.

%------------------------------------------%
% Page 504 Top

Calculation of the likelihood displacement

\begin{framed}
\begin{verbatim}

lLik <- function(cx)
   {
   lmeU <- lmeUall[[cx]]
   lLikU <- logLik(lmeU, REML = FALSE)
   df.s <- subset(armd,subject == cx)
 
   lLik.s <- logLik1(lmeU,df.s)

   return(lLikU + lLik.s)
   }

lLikUall <- apply(subject.c,lLik)

\end{verbatim}
\end{framed}

%--------------------%
% Part 2
% Plot of the likelihood displacement with an indication of outlying values.
%

\begin{framed}
\begin{verbatim}

names(dif.2Lik) <- subject.c #subjects ids assigned
outL <- dif.2Lik > 0.5

dif.2Lik[outL]

## Plot Component

libary(lattice)

subject.f <- factor(subject.c, levels = subject.c)

myPanel <- function(x,y, ...){
  x1 <- as.numeric(x)
  panel.xyplot(x1,y, ... )
  ltext(x1[outL],y[outL], subject.c[outL]) # outlying LDis
  }

dtp <- dotplot(dif.2Lik ~subject.f, panel = myPanel, type= "h")

 # ggplot?
lxlims <- length(dtp$x.limits)

update(dtp,xlim=rep(" ", lxlims),grid= "h")
\end{verbatim}
\end{framed}

%------------------------------------------%
% Page 505 Top

By applying the \texttt{summary()} function to the vector, we obtain summary statistics of the computed likelihood-displacement values.

we create the logical output vector outL which indicates the subjects with the values of the 
likelihood displacement exceeding say 0.5.

From the printout of the selected elements of the vectir dif.2Lik it follows that there are
seven such subjects.


We then use the function \texttt{dotplot()} from the package lattice to plot the 
likelihood distance value for all subjects.

The x-axis of the plot is constructed using numeric representation of the \texttt{numeric.f} factor, containing values ranging from 1 to 234.
%------------------------------------------%
% Page 505 Bottom
\section{20.3.2.3. Cook's Distance for the $\beta$ estimates}

Cook's distance for the $\beta$ estimates was defined in (4.26) for the classical LM.
The definition can be extended to the LMMs in a straightforward manner.

%------------------------------------------%
% Page 506 top

Part 2 plot of cook's distance using traditional graphics

# Annotation Component

\begin{framed}
\begin{verbatim}

betaUall <- sapply(lmeUall,fixef)

vb.inv <- solve(vcovb)

cookDfun <- function(betaU){
   dbetaU <- betaU - beta0
   cookD.value <- t(dbetaU) %*% vb.inv %*% dbetaU
   }
\end{verbatim}
\end{framed}

%----------------%
Plot of Cook's Distance using traditional graphics. 
Outlying values annotated.

\begin{framed}
\begin{verbatim}
outD <- cookD > 0.03


#Create the Stick plot
plot(CookD ~subject.c, 
  ylab="Cook's Distance", type="h")

text()
points()
\end{verbatim}
\end{framed}

%------------------------------------------%
% Page 506 bottom 
Cook's distance for the $beta$ estimates were defined bu 4.26 for the classical LM model.


Next we compute the inverse of the variance covariance matrix \hat{\beta} using the solve() function.
We store the resulting matrix in the object \texttt{vb.inv}.

Subsequently we define the function \texttt{cookDfun()} which, for a vector given in
the \texttt{betaU} argument, computes the value of the numerator of Cook's Distance, as in (4.26).

The function is then applied sequentially to all columns of the matrix \texttt{betaUall}.


The resultant vector is divided by the number of the fixed effects coefficients, which, under the assumption that the design matrix is of full rank, 
is equivalent to the rank of the design matrix.

%------------------------------------------%
% Page 507 all


The outcome is stored in the vector \textt{cookD} and contains the values of cooks distanced for all subjects.

We create the logical vector outD which indicates the subjects with cook's distance values that exceed 0.03.

Present the scatterplot matrix of the two-dimensional projections of the differences.
\[  \frac{\hat{\textbf{beta}_{(-i)} - \hat{\textbf{beta}} }{\hat{se}(\hat{beta})} \]
for all pairs of the fixed-effects coefficients.

%-------%
The plot was generated using the \texttt{splom} function. The main argument of the 
function was obtained by subtracting the beta0 vector from the rows of the transposed
betaUall matrix.

%-------%
The labels used in the panels located on the diagonal of the figure provide the fixed estimates of fixed effects coefficients
of the model and their estimates SEs.
The panels above the diagonal include points for all subjects.
The points for non-outlying values are plotted using small size open circles.
The five outlying values are plotted using different plotting symbols defined in the
legend of the figure at the top of the graph.

%------------------------------------------%
% Page 508 All +  top of Page 509

The effect of removal of this subject on the estimates of the remaining fixed-effects coefficients is relatively small.
In contrast, removing the subject ``227" affects the estimate of all fixed-effects coefficients to a different degree and in different directions.

More specifically, the intercept is driven towards lower values : the positive slope associated with visual acuity at baseline visual0, is further increased, the negative slope associated with \texttt{time} is brough closer to zero, and the treatment effect is attenuated.

% Top of Page 509

Overall we note that the effect of removing any of the subjects on the fixed effects estimates is very small, as it does not exceed 0.05 of the SE of any of the  estimates.

%-------------------------------------------%
%Page 509 Top
\section{Simulation of the Dependent Variable}

We cosnider simualtions of the dependent variable, based on the marginal distribution 
implied by the fitted model.
Towards this end, we have developed \texttt{simulateY()}, which can be used for objects of class lme.

We note that the function is different from simulate.lme(), available in the nlme in that the latter returns
simulation-based REML and/or ML values and not the value of the dependent variable.

We demonstrate the use of the \texttt{simulateY()} function to create the empirical distribution of the \textbf{\beta} estimates.
As an example, we consider the model which was fitted to the armd data.

Note however that the presented syntax is fairly general can be used for other LMEs as well.

We apply the function \texttt{simulateY()} to the object fm16.5ml.


%-------------------------------------------%
%Page 509 Bottom

\begin{framed}
\begin{verbatim}
library(nlmeU)
simY <- simulateY(fm16.5ml, nsim=1000)


simYsumm <- apply( simY, MARGIN = 2, 
 FUN = function(y){

     }
   )


simYsumm[[1]]

# \hat{\beta} for the 1st simulation
\end{verbatim}
\end{framed}
%--------------------------------------------%
% Page 510 Top

There is a second argument \texttt{nsim} that indicated how many simulations 

The auxillary function performs the following steps

\begin{itemize}
\item the dependent variable visual is the \texttt{auxDt} data frame is replaced wiht a new set of simulated values contained in the vector $y$.
\item Model M16.5 is fitted to the modified data frame
\item the vector beta with the estimates of the fixed effects coefficients is extracted from the summary of the model-fit object with the help of the \texttt{fixef()} function.
\item The vector of estimates is returned as a list with one component named \texttt{beta}.
\end{itemize}

They are drawn from the marginal distribution of the dependent variable implied by the fitted model.

%--------------------------------------------%
% Page 510 Bottom


It should be mentioned that the creation of the simYsumm list involves refitting the model many times, and it therefore takes a long time.

Toward this end, with the help of the \texttt{sapply()} function, we extrac the vectors with the values of \hat{\beta} for each simulation for the list
-object \texttt{simYsumm} and bind them column-wise into the \texttt{betaE}.

Then we use the function \texttt{rowMeans()} to compute the mean values of the columns (i.e. accross the rows) of betaE.



%--------------------------------------------%


